# DescriÃ§Ã£o do Projeto
 
Este projeto realiza a leitura de arquivos JSON e os envia para um sistema de processamento em tempo real utilizando Kafka e PyFlink. O objetivo Ã© capturar e processar dados em tempo real de maneira organizada.
 
## Funcionalidades
 
- Mapeamento de arquivos JSON de entrada na pasta `src/app/data/in`.
- Envio dos arquivos mapeados para um tÃ³pico do Kafka.
- Leitura dos dados em tempo real com PyFlink e escrita dos dados processados em arquivos de saÃ­da na pasta `src/app/data/out`.
- Os arquivos de saÃ­da sÃ£o organizados em pastas no formato `YYYY-MM-DD--HH`, facilitando a organizaÃ§Ã£o e recuperaÃ§Ã£o dos dados.

## Estrutura do Projeto
```
ğŸ“¦ root
â”œâ”€â”€ ğŸ“ src/                  	# Pasta que contÃ©m os principais arquivos
â”‚   â”œâ”€â”€ ğŸ“ data/             	# Dados de entrada e saÃ­da do pipeline
â”‚   â”‚   â”œâ”€â”€ ğŸ“ in/   	      	# Dados de entrada
â”‚   â”‚   â””â”€â”€ ğŸ“ out/      	# Dados de saÃ­da
â”‚   â”œâ”€â”€ ğŸ“ jar/               	# Pasta que contÃ©m o arquivo .jar
â”‚   â”‚   â””â”€â”€ ğŸ“„ flink-sql-connector-kafka.jar 	# Arquivo .jar
â”‚   â”œâ”€â”€ ğŸ“„ consumer.py         	# Arquivo .py do consumer
â”‚   â””â”€â”€ ğŸ“„ producer.py       	# Arquivo .py do producer
â”œâ”€â”€ ğŸ“„ .env  			# Arquivo com as variÃ¡veis de ambiente
â”œâ”€â”€ ğŸ“„ docker-compose.yml  	# Arquivo do composer
â”œâ”€â”€ ğŸ“„ poetry.lock  		# Arquivo de dependÃªncias do poetry
â”œâ”€â”€ ğŸ“„ pyproject.toml  		# Arquivo de dependÃªncias do poetry
â””â”€â”€ ğŸ“„ README.md              	# Arquivo README principal do projeto
```
 
## Como Executar o Projeto (Windows)?
**OBS:** Caso ocorra algum tipo de erro na leitura das variÃ¡veis de ambiente (arquivo .env), fechar e reabrir o terminal para que o ambiente virtual seja reinicializado corretamente.
1. Instalar o pyenv-win via PowerShell:
`Invoke-WebRequest -UseBasicParsing -Uri "https://raw.githubusercontent.com/pyenv-win/pyenv-win/master/pyenv-win/install-pyenv-win.ps1" -OutFile "./install-pyenv-win.ps1"; &"./install-pyenv-win.ps1"` 
2. Na pasta do projeto (root) executar o comando: `pyenv local 3.11.7`
3. Instale o [Poetry](https://python-poetry.org/) para gerenciamento de dependÃªncias: `pip install poetry`
4.  Instale as dependÃªncias do projeto:
	   `poetry install --only main` 
3.  Configure o caminho do arquivo `.jar` necessÃ¡rio para o PyFlink:
	   -   Localize o arquivo `.jar` na pasta `src/app/jar`.
	   -   Edite a variÃ¡vel `PATH_JAR` no arquivo `.env` para apontar para o caminho completo do arquivo `.jar`.
4.  Inicie os containers do Docker (necessÃ¡rio para rodar o Kafka e outros serviÃ§os): `docker-compose up -d`
5.  Em terminais separados, execute os seguintes comandos para iniciar o consumidor e o produtor:
   `poetry run python src/app/consumer.py`
   `poetry run python src/app/producer.py`

 
Agora, o sistema estÃ¡ configurado para capturar os dados JSON de entrada, processÃ¡-los em tempo real e salvar os resultados na estrutura de saÃ­da especificada.
 
## Tecnologias Utilizadas
 
-   Kafka
-   PyFlink
-   Poetry
-   Python
-   Docker
